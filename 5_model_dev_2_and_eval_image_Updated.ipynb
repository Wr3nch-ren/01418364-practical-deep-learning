{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1877 files belonging to 2 classes.\n",
      "Using 1314 files for training.\n",
      "Using 563 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_data, valid_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"./cats_vs_dogs\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(150, 150),\n",
    "    validation_split=0.3,\n",
    "    subset=\"both\",\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'dog']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = train_data.class_names\n",
    "n_classes = len(classes)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=18>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches = valid_data.cardinality()\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = n_batches // 2\n",
    "test_data = valid_data.take(test_size)\n",
    "valid_data = valid_data.skip(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "for transform in [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "]:\n",
    "    train_data = train_data.map(lambda x, y: (transform(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83683744/83683744 [==============================] - 8s 0us/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.optimizers' has no attribute 'AdamW'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m\n\u001b[0;32m     26\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     27\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdamW(),\n\u001b[0;32m     28\u001b[0m         loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(),\n\u001b[0;32m     29\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mCategoricalAccuracy()],\n\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 34\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39msummary(show_trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m     23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(n_classes)(outputs)\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs, outputs)\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m---> 27\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m(),\n\u001b[0;32m     28\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(),\n\u001b[0;32m     29\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mCategoricalAccuracy()],\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.optimizers' has no attribute 'AdamW'"
     ]
    }
   ],
   "source": [
    "def create_model(hp=None):\n",
    "    base_model = tf.keras.applications.Xception(\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(150, 150, 3),\n",
    "        include_top=False,\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(150, 150, 3))\n",
    "    scaling = tf.keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "    outputs = scaling(inputs)\n",
    "    outputs = base_model(outputs, training=False)\n",
    "    outputs = tf.keras.layers.GlobalAveragePooling2D()(outputs)\n",
    "\n",
    "    #hp : hyper parameter\n",
    "    hp_layers = hp.Int(\"layers\", min_value=1, max_value=3, step=1) if hp else 1 # step ขยับค่ทีละเท่าไหร่\n",
    "    hp_units = hp.Int(\"units\", min_value=32, max_value=128, step=32) if hp else 32 # if else are default \n",
    "    \n",
    "    for _ in range(hp_layers):\n",
    "        outputs = tf.keras.layers.Dense(hp_units)(outputs)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(n_classes)(outputs)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.AdamW(),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 Complete [00h 01m 17s]\n",
      "categorical_accuracy: 0.5404376983642578\n",
      "\n",
      "Best categorical_accuracy So Far: 0.5842055082321167\n",
      "Total elapsed time: 1d 00h 36m 06s\n",
      "\n",
      "Search: Running Trial #17\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1                 |1                 |layers\n",
      "96                |96                |units\n",
      "10                |4                 |tuner/epochs\n",
      "4                 |2                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "2                 |1                 |tuner/round\n",
      "0012              |0009              |tuner/trial_id\n",
      "\n",
      "Epoch 5/10\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras-tuner\n",
    "\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel=create_model,\n",
    "    objective=\"categorical_accuracy\",\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    project_name=\"cats_vs_dogs_hp\"\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "X_train = np.concatenate([x for x, _ in train_data], axis=0)\n",
    "y_train = np.concatenate([y for _, y in train_data], axis=0)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=10, validation_split=0.2, callbacks=[stop_early])\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33/33 [==============================] - 12s 333ms/step - loss: 0.9944 - categorical_accuracy: 0.5214 - val_loss: 0.6946 - val_categorical_accuracy: 0.4905\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 13s 391ms/step - loss: 0.6882 - categorical_accuracy: 0.4643 - val_loss: 0.6953 - val_categorical_accuracy: 0.4905\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 15s 456ms/step - loss: 0.6844 - categorical_accuracy: 0.4386 - val_loss: 0.6982 - val_categorical_accuracy: 0.5057\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 15s 453ms/step - loss: 0.6774 - categorical_accuracy: 0.4291 - val_loss: 0.7045 - val_categorical_accuracy: 0.5019\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 15s 453ms/step - loss: 0.6912 - categorical_accuracy: 0.4415 - val_loss: 0.7151 - val_categorical_accuracy: 0.4829\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 15s 455ms/step - loss: 0.6683 - categorical_accuracy: 0.4110 - val_loss: 0.7422 - val_categorical_accuracy: 0.4829\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 15s 453ms/step - loss: 0.6405 - categorical_accuracy: 0.3625 - val_loss: 0.7280 - val_categorical_accuracy: 0.4867\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 15s 453ms/step - loss: 0.5951 - categorical_accuracy: 0.3054 - val_loss: 1.1371 - val_categorical_accuracy: 0.4905\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 15s 454ms/step - loss: 0.6580 - categorical_accuracy: 0.3149 - val_loss: 0.7356 - val_categorical_accuracy: 0.4943\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 15s 453ms/step - loss: 0.6001 - categorical_accuracy: 0.3016 - val_loss: 1.3398 - val_categorical_accuracy: 0.4981\n",
      "Best epoch: 3\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history[\"val_categorical_accuracy\"]\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print(\"Best epoch: %d\" % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8/8 [==============================] - 5s 495ms/step - loss: 1.2009 - categorical_accuracy: 0.5087 - val_loss: 0.5547 - val_categorical_accuracy: 0.6034\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 3s 431ms/step - loss: 0.4882 - categorical_accuracy: 0.7652 - val_loss: 0.4687 - val_categorical_accuracy: 0.8966\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 3s 440ms/step - loss: 0.4101 - categorical_accuracy: 0.8826 - val_loss: 0.3821 - val_categorical_accuracy: 0.9138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c5ba71dd50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.concatenate([x for x, _ in test_data], axis=0)\n",
    "y_test = np.concatenate([y for _, y in test_data], axis=0)\n",
    "\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "hypermodel.fit(X_test, y_test, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 369ms/step - loss: 0.3588 - categorical_accuracy: 0.9132\n",
      "[test loss, test accuracy]: [0.35881656408309937, 0.9131944179534912]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(X_test, y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
