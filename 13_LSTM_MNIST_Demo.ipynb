{"cells":[{"cell_type":"markdown","metadata":{"id":"a4TqmwytMCf6"},"source":["# Recurrent Neural Networks - Deep Learning basics with Python, TensorFlow and Keras p.7\n","#### by sentdex from https://pythonprogramming.net/recurrent-neural-network-deep-learning-python-tensorflow-keras/"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"SN9es6i_MCf-"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.layers import LSTM, Conv2D, MaxPooling2D, Flatten"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"dlMgcdZJMCf_"},"outputs":[],"source":["mnist = tf.keras.datasets.mnist  # mnist is a dataset of 28x28 images of handwritten digits and their labels\n","(X_train, y_train),(X_test, y_test) = mnist.load_data()  # unpacks images to X_train/X_test and labels to y_train/y_test"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"sl3bZf2JMCf_","outputId":"4f9970d9-e77f-4b8f-99ef-d96f430712cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["(60000, 28, 28)\n","(28, 28)\n"]}],"source":["X_train = X_train/255.0\n","X_test = X_test/255.0\n","\n","print(X_train.shape)\n","print(X_train[0].shape)"]},{"cell_type":"markdown","metadata":{"id":"qdP27qmAMCgA"},"source":["### Using MLP (for comparison)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zoq1sPI1MCgA"},"outputs":[],"source":["# Fill your code here"]},{"cell_type":"markdown","metadata":{"id":"oyT17wvUMCgB"},"source":["### Using CNN (for comparison)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"tKvxYvhIMCgB","outputId":"d7470960-ca72-4ad3-eb75-a8ccd66c800c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","1875/1875 [==============================] - 16s 7ms/step - loss: 0.3022 - accuracy: 0.9036 - val_loss: 0.0702 - val_accuracy: 0.9773\n","Epoch 2/3\n","1875/1875 [==============================] - 13s 7ms/step - loss: 0.1188 - accuracy: 0.9639 - val_loss: 0.0542 - val_accuracy: 0.9810\n","Epoch 3/3\n","1875/1875 [==============================] - 13s 7ms/step - loss: 0.0897 - accuracy: 0.9732 - val_loss: 0.0442 - val_accuracy: 0.9853\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1513cd71540>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(*X_train.shape[1:], 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.1))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(10, activation='softmax'))\n","\n","lr_scheduler = tf.keras.optimizers.schedules.InverseTimeDecay(\n","    0.001, decay_rate=1e-6, decay_steps=1, staircase=False)\n","opt = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n","\n","# Compile model\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))"]},{"cell_type":"markdown","metadata":{"id":"J9AKkT_tMCgB"},"source":["### Using LSTM"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"gC6YpC8tMCgB","outputId":"67d698c5-bc11-462a-96b8-3e62bf4cbb2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/3\n","1875/1875 [==============================] - 261s 138ms/step - loss: 0.5906 - accuracy: 0.8067 - val_loss: 0.1750 - val_accuracy: 0.9479\n","Epoch 2/3\n","1875/1875 [==============================] - 258s 138ms/step - loss: 0.1449 - accuracy: 0.9610 - val_loss: 0.0895 - val_accuracy: 0.9742\n","Epoch 3/3\n","1875/1875 [==============================] - 255s 136ms/step - loss: 0.1017 - accuracy: 0.9730 - val_loss: 0.0781 - val_accuracy: 0.9779\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1514b883cd0>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model = Sequential()\n","\n","model.add(LSTM(128, input_shape=X_train.shape[1:], activation='relu', return_sequences=True))\n","model.add(Dropout(0.2))\n","\n","model.add(LSTM(128, activation='relu'))\n","model.add(Dropout(0.1))\n","\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(10, activation='softmax'))\n","\n","lr_scheduler = tf.keras.optimizers.schedules.InverseTimeDecay(\n","    0.001, decay_rate=1e-6, decay_steps=1, staircase=False)\n","opt = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n","\n","# Compile model\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"dl_env","language":"python","name":"dl_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
